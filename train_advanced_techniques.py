#!/usr/bin/env python3
"""
Advanced Training Script with Self-Supervised Learning, Adversarial Training, and Uncertainty Quantification
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import yaml
import argparse
import os
from pathlib import Path
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

from src.advanced_training import AdvancedTrainer, MaskedAutoencoder, AdversarialTrainer, UncertaintyQuantifier
from src.advanced_models import create_advanced_model
from src.data_loader import DataManager
from src.evaluator import evaluate_model


class AdvancedTrainingPipeline:
    """Complete advanced training pipeline"""
    
    def __init__(self, config, model_type="hybrid_cnn_vit"):
        self.config = config
        self.model_type = model_type
        self.device = torch.device("mps" if torch.backends.mps.is_available() else 
                                 "cuda" if torch.cuda.is_available() else "cpu")
        
        # Create model
        self.model = create_advanced_model(model_type, config)
        self.model = self.model.to(self.device)
        
        # Initialize advanced trainer
        self.advanced_trainer = AdvancedTrainer(config, self.model)
        
        # Training components
        self.optimizer = self._setup_optimizer()
        self.scheduler = self._setup_scheduler()
        self.criterion = self._setup_criterion()
        
        # Training history
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_acc': [],
            'val_acc': [],
            'adversarial_loss': [],
            'uncertainty_entropy': [],
            'mae_loss': []
        }
        
        # Best model tracking
        self.best_val_acc = 0.0
        self.patience_counter = 0
    
    def _setup_optimizer(self):
        """Setup optimizer with different learning rates"""
        backbone_params = []
        head_params = []
        
        for name, param in self.model.named_parameters():
            if 'backbone' in name or 'cnn_backbone' in name:
                backbone_params.append(param)
            else:
                head_params.append(param)
        
        return optim.AdamW([
            {'params': backbone_params, 'lr': 1e-5},  # Lower LR for pretrained parts
            {'params': head_params, 'lr': 1e-4}       # Higher LR for new parts
        ], weight_decay=0.01)
    
    def _setup_scheduler(self):
        """Setup learning rate scheduler"""
        return optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=10, T_mult=2, eta_min=1e-7
        )
    
    def _setup_criterion(self):
        """Setup loss function with uncertainty weighting"""
        class UncertaintyWeightedLoss(nn.Module):
            def __init__(self, base_criterion, uncertainty_weight=0.1):
                super().__init__()
                self.base_criterion = base_criterion
                self.uncertainty_weight = uncertainty_weight
            
            def forward(self, outputs, targets, uncertainty=None):
                base_loss = self.base_criterion(outputs, targets)
                
                if uncertainty is not None:
                    uncertainty_loss = uncertainty.mean()
                    return base_loss + self.uncertainty_weight * uncertainty_loss
                
                return base_loss
        
        return UncertaintyWeightedLoss(nn.CrossEntropyLoss(), uncertainty_weight=0.1)
    
    def pretrain_with_mae(self, train_loader, epochs=20):
        """Self-supervised pre-training with MAE"""
        print("üéØ Starting MAE pre-training...")
        
        self.advanced_trainer.pretrain_mae(train_loader, epochs)
        
        # Transfer MAE weights to main model (if compatible)
        try:
            # This would require careful weight transfer based on architecture
            print("‚úÖ MAE pre-training completed!")
        except Exception as e:
            print(f"‚ö†Ô∏è MAE pre-training completed, but weight transfer failed: {e}")
    
    def train_epoch_advanced(self, train_loader, use_adversarial=True, use_uncertainty=True):
        """Advanced training epoch with adversarial training and uncertainty quantification"""
        self.model.train()
        total_loss = 0.0
        total_adv_loss = 0.0
        total_uncertainty = 0.0
        correct = 0
        total = 0
        
        pbar = tqdm(train_loader, desc="Advanced Training")
        for batch_idx, (data, target) in enumerate(pbar):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            
            # Standard forward pass
            output = self.model(data)
            standard_loss = self.criterion(output, target)
            
            total_loss += standard_loss.item()
            
            # Adversarial training
            if use_adversarial and batch_idx % 3 == 0:  # Apply every 3rd batch
                try:
                    adv_loss, adv_data = self.advanced_trainer.adversarial_training_step(
                        data, target, nn.CrossEntropyLoss(), attack_type='fgsm'
                    )
                    total_adv_loss += adv_loss.item()
                    standard_loss = adv_loss
                except Exception as e:
                    print(f"Adversarial training failed: {e}")
            
            # Uncertainty-aware training
            if use_uncertainty and batch_idx % 5 == 0:  # Apply every 5th batch
                try:
                    uncertainty_loss, entropy = self.advanced_trainer.uncertainty_aware_training(
                        data, target, nn.CrossEntropyLoss()
                    )
                    total_uncertainty += entropy.mean().item()
                    standard_loss = uncertainty_loss
                except Exception as e:
                    print(f"Uncertainty training failed: {e}")
            
            # Backward pass
            standard_loss.backward()
            
            # Gradient clipping
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            # Statistics
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
            
            # Update progress bar
            pbar.set_postfix({
                'Loss': f'{standard_loss.item():.4f}',
                'Acc': f'{100. * correct / total:.2f}%'
            })
        
        avg_loss = total_loss / len(train_loader)
        avg_adv_loss = total_adv_loss / len(train_loader)
        avg_uncertainty = total_uncertainty / len(train_loader)
        accuracy = 100. * correct / total
        
        self.history['train_loss'].append(avg_loss)
        self.history['train_acc'].append(accuracy)
        self.history['adversarial_loss'].append(avg_adv_loss)
        self.history['uncertainty_entropy'].append(avg_uncertainty)
        
        return avg_loss, accuracy, avg_adv_loss, avg_uncertainty
    
    def validate_epoch(self, val_loader):
        """Validation epoch with uncertainty quantification"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        all_entropies = []
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                
                # Standard prediction
                output = self.model(data)
                loss = self.criterion(output, target)
                
                total_loss += loss.item()
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
                
                # Uncertainty quantification
                try:
                    mean_pred, var_pred, entropy = self.advanced_trainer.uncertainty_quantifier.monte_carlo_dropout(data)
                    all_entropies.extend(entropy.cpu().numpy())
                except Exception as e:
                    pass  # Skip uncertainty if it fails
        
        avg_loss = total_loss / len(val_loader)
        accuracy = 100. * correct / total
        avg_entropy = np.mean(all_entropies) if all_entropies else 0.0
        
        self.history['val_loss'].append(avg_loss)
        self.history['val_acc'].append(accuracy)
        
        return avg_loss, accuracy, avg_entropy
    
    def train_advanced(self, train_loader, val_loader, epochs=30, 
                      use_mae_pretraining=True, use_adversarial=True, use_uncertainty=True):
        """Complete advanced training pipeline"""
        print(f"üöÄ Starting Advanced Training Pipeline")
        print(f"üì± Device: {self.device}")
        print(f"üî¢ Parameters: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"üéØ Features: MAE={use_mae_pretraining}, Adversarial={use_adversarial}, Uncertainty={use_uncertainty}")
        
        # MAE Pre-training
        if use_mae_pretraining:
            self.pretrain_with_mae(train_loader, epochs=10)
        
        # Main training loop
        for epoch in range(epochs):
            print(f"\nüìÖ Epoch {epoch+1}/{epochs}")
            
            # Training
            train_loss, train_acc, adv_loss, uncertainty = self.train_epoch_advanced(
                train_loader, use_adversarial, use_uncertainty
            )
            
            # Validation
            val_loss, val_acc, val_entropy = self.validate_epoch(val_loader)
            
            # Learning rate scheduling
            self.scheduler.step()
            
            # Print epoch results
            print(f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
            print(f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
            if use_adversarial:
                print(f"Adversarial Loss: {adv_loss:.4f}")
            if use_uncertainty:
                print(f"Uncertainty Entropy: {uncertainty:.4f}")
            print(f"LR: {self.optimizer.param_groups[0]['lr']:.2e}")
            
            # Save best model
            if val_acc > self.best_val_acc:
                self.best_val_acc = val_acc
                self.patience_counter = 0
                self.save_model(f"models/best_advanced_{self.model_type}_model.pth")
                print(f"üíæ New best model saved! Val Acc: {val_acc:.2f}%")
            else:
                self.patience_counter += 1
            
            # Early stopping
            if self.patience_counter >= self.config['training']['early_stopping_patience']:
                print(f"üõë Early stopping after {epoch+1} epochs")
                break
        
        # Plot training curves
        self.plot_advanced_training_curves()
        
        print(f"\nüéâ Advanced training completed! Best validation accuracy: {self.best_val_acc:.2f}%")
    
    def evaluate_uncertainty(self, test_loader):
        """Evaluate model uncertainty"""
        print("\nüîç Evaluating model uncertainty...")
        
        uncertainty_stats, entropies, epistemic, aleatoric = self.advanced_trainer.evaluate_uncertainty(test_loader)
        
        print(f"üìä Uncertainty Statistics:")
        print(f"   Mean Entropy: {uncertainty_stats['mean_entropy']:.4f}")
        print(f"   Mean Epistemic: {uncertainty_stats['mean_epistemic']:.4f}")
        print(f"   Mean Aleatoric: {uncertainty_stats['mean_aleatoric']:.4f}")
        print(f"   Uncertainty Correlation: {uncertainty_stats['uncertainty_correlation']:.4f}")
        
        # Plot uncertainty analysis
        self.advanced_trainer.plot_uncertainty_analysis(uncertainty_stats, entropies, epistemic, aleatoric)
        
        return uncertainty_stats
    
    def save_model(self, path):
        """Save model checkpoint"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_val_acc': self.best_val_acc,
            'config': self.config,
            'model_type': self.model_type,
            'training_history': self.history
        }, path)
    
    def plot_advanced_training_curves(self):
        """Plot advanced training curves"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        fig.suptitle('Advanced Training Curves', fontsize=16, fontweight='bold')
        
        # Loss curves
        ax1 = axes[0, 0]
        ax1.plot(self.history['train_loss'], label='Train Loss', color='blue')
        ax1.plot(self.history['val_loss'], label='Val Loss', color='red')
        ax1.set_title('Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # Accuracy curves
        ax2 = axes[0, 1]
        ax2.plot(self.history['train_acc'], label='Train Acc', color='blue')
        ax2.plot(self.history['val_acc'], label='Val Acc', color='red')
        ax2.set_title('Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        # Adversarial loss
        ax3 = axes[0, 2]
        if self.history['adversarial_loss']:
            ax3.plot(self.history['adversarial_loss'], label='Adversarial Loss', color='orange')
            ax3.set_title('Adversarial Training Loss')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Loss')
            ax3.legend()
            ax3.grid(True)
        else:
            ax3.text(0.5, 0.5, 'Adversarial Training\nNot Used', ha='center', va='center', transform=ax3.transAxes)
            ax3.set_title('Adversarial Training Loss')
        
        # Uncertainty entropy
        ax4 = axes[1, 0]
        if self.history['uncertainty_entropy']:
            ax4.plot(self.history['uncertainty_entropy'], label='Uncertainty Entropy', color='green')
            ax4.set_title('Uncertainty Entropy')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Entropy')
            ax4.legend()
            ax4.grid(True)
        else:
            ax4.text(0.5, 0.5, 'Uncertainty Training\nNot Used', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Uncertainty Entropy')
        
        # MAE loss
        ax5 = axes[1, 1]
        if self.history['mae_loss']:
            ax5.plot(self.history['mae_loss'], label='MAE Loss', color='purple')
            ax5.set_title('MAE Pre-training Loss')
            ax5.set_xlabel('Epoch')
            ax5.set_ylabel('Loss')
            ax5.legend()
            ax5.grid(True)
        else:
            ax5.text(0.5, 0.5, 'MAE Pre-training\nNot Used', ha='center', va='center', transform=ax5.transAxes)
            ax5.set_title('MAE Pre-training Loss')
        
        # Learning rate
        ax6 = axes[1, 2]
        lrs = [group['lr'] for group in self.optimizer.param_groups]
        ax6.plot(lrs, label='Learning Rate', color='brown')
        ax6.set_title('Learning Rate Schedule')
        ax6.set_xlabel('Epoch')
        ax6.set_ylabel('Learning Rate')
        ax6.legend()
        ax6.grid(True)
        
        plt.tight_layout()
        plt.savefig(f'models/advanced_training_curves_{self.model_type}.png', dpi=300, bbox_inches='tight')
        plt.show()


def main():
    parser = argparse.ArgumentParser(description='Advanced Training with Self-Supervised Learning, Adversarial Training, and Uncertainty Quantification')
    parser.add_argument('--model_type', type=str, default='hybrid_cnn_vit',
                       choices=['hybrid_cnn_vit', 'multiscale_vit'],
                       help='Type of advanced model to train')
    parser.add_argument('--epochs', type=int, default=30, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=16, help='Batch size')
    parser.add_argument('--config', type=str, default='configs/config.yaml', help='Config file path')
    parser.add_argument('--use_mae', action='store_true', help='Use MAE pre-training')
    parser.add_argument('--use_adversarial', action='store_true', help='Use adversarial training')
    parser.add_argument('--use_uncertainty', action='store_true', help='Use uncertainty quantification')
    
    args = parser.parse_args()
    
    # Load configuration
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # Update config with command line arguments
    config['training']['epochs'] = args.epochs
    config['data']['batch_size'] = args.batch_size
    
    # Create data loaders
    print("üìä Loading data...")
    data_manager = DataManager(config)
    train_loader, val_loader, test_loader, class_names = data_manager.create_dataloaders()
    
    # Create advanced training pipeline
    pipeline = AdvancedTrainingPipeline(config, args.model_type)
    
    # Train with advanced techniques
    pipeline.train_advanced(
        train_loader, val_loader, args.epochs,
        use_mae_pretraining=args.use_mae,
        use_adversarial=args.use_adversarial,
        use_uncertainty=args.use_uncertainty
    )
    
    # Evaluate uncertainty
    uncertainty_stats = pipeline.evaluate_uncertainty(test_loader)
    
    # Final evaluation
    print("\nüß™ Final evaluation on test set...")
    test_metrics = evaluate_model(pipeline.model, test_loader, class_names, pipeline.device)
    
    print(f"\nüìä Final Test Results for {args.model_type}:")
    for metric, value in test_metrics.items():
        print(f"{metric}: {value:.4f}")


if __name__ == "__main__":
    main()
